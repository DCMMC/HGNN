Using random seed:  1000
/data/xwt/HGNN/config/config.py:21: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  cfg = yaml.load(f)
Using cora dataset
max degree: 169, mean degree:4.89807976366322
----------
Epoch 0/599
/data/xwt/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:117: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
train Loss: 0.0139 Acc: 0.1429
val Loss: 0.0039 Acc: 0.1080
Best val Acc: 0.108000, Min val loss: 0.003891
--------------------
----------
Epoch 50/599
train Loss: 0.0100 Acc: 0.4357
val Loss: 0.0031 Acc: 0.3520
Best val Acc: 0.366000, Min val loss: 0.003141
--------------------
----------
Epoch 100/599
train Loss: 0.0060 Acc: 0.5643
val Loss: 0.0036 Acc: 0.5420
Best val Acc: 0.542000, Min val loss: 0.003025
--------------------
----------
Epoch 150/599
train Loss: 0.0040 Acc: 0.7857
val Loss: 0.0045 Acc: 0.5340
Best val Acc: 0.582000, Min val loss: 0.003025
--------------------
----------
Epoch 200/599
train Loss: 0.0028 Acc: 0.8714
val Loss: 0.0043 Acc: 0.6220
Best val Acc: 0.638000, Min val loss: 0.003025
--------------------
----------
Epoch 250/599
train Loss: 0.0016 Acc: 0.9500
val Loss: 0.0052 Acc: 0.6420
Best val Acc: 0.666000, Min val loss: 0.003025
--------------------
----------
Epoch 300/599
train Loss: 0.0009 Acc: 0.9786
val Loss: 0.0060 Acc: 0.6460
Best val Acc: 0.680000, Min val loss: 0.003025
--------------------
----------
Epoch 350/599
train Loss: 0.0009 Acc: 0.9643
val Loss: 0.0058 Acc: 0.6740
Best val Acc: 0.682000, Min val loss: 0.003025
--------------------
----------
Epoch 400/599
train Loss: 0.0005 Acc: 0.9714
val Loss: 0.0068 Acc: 0.6740
Best val Acc: 0.688000, Min val loss: 0.003025
--------------------
----------
Epoch 450/599
train Loss: 0.0004 Acc: 0.9857
val Loss: 0.0071 Acc: 0.6580
Best val Acc: 0.688000, Min val loss: 0.003025
--------------------
----------
Epoch 500/599
train Loss: 0.0009 Acc: 0.9571
val Loss: 0.0073 Acc: 0.6580
Best val Acc: 0.688000, Min val loss: 0.003025
--------------------
----------
Epoch 550/599
train Loss: 0.0002 Acc: 0.9929
val Loss: 0.0094 Acc: 0.6400
Best val Acc: 0.688000, Min val loss: 0.003025
--------------------

Training complete in 0m 8s

State dict updates 82
Best val Acc: 0.688000
**** Model of lowest val loss ****
********************
Test acc: 0.463 @Epoch-54
********************
**** Model of best val acc ****
********************
Test acc: 0.686 @Epoch-383
********************
